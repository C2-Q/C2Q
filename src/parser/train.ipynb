{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T07:46:12.575693Z",
     "start_time": "2025-05-22T07:46:12.572925Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:46:14.527847Z",
     "start_time": "2025-05-22T07:46:14.524305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using {device}\")"
   ],
   "id": "4f11c30600f651ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:46:16.699309Z",
     "start_time": "2025-05-22T07:46:16.125695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset\n",
    "dataset = load_dataset('csv', data_files={'data': 'data.csv'})"
   ],
   "id": "97b65ea93a91eb2d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:46:19.569047Z",
     "start_time": "2025-05-22T07:46:18.406559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenizer, pretrained \n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    code_snippet = examples['code_snippet']\n",
    "    return tokenizer(code_snippet, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset['data'].map(tokenize_function, batched=True)\n",
    "\n",
    "# tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ],
   "id": "8b4fb4aa5f610446",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:46:40.750834Z",
     "start_time": "2025-05-22T07:46:24.406925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=10)\n",
    "model.to(device) # move model to mps or cpu\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
    "    num_train_epochs=10,          # Number of epochs\n",
    "    per_device_train_batch_size=8,  # Batch size (adjust based on memory)\n",
    "    per_device_eval_batch_size=16,  # Batch size for evaluation\n",
    "    logging_strategy=\"steps\",     # Log training loss every few steps\n",
    "    logging_steps=50,             # Log every 50 steps\n",
    "    logging_dir=\"./logs\",         # Auxiliary for tensorboard\n",
    "    save_strategy=\"epoch\",        # Save model after every epoch\n",
    "    load_best_model_at_end=True,  # Load best model when finished training\n",
    "    report_to=\"tensorboard\",             # Report to tensorboard for visualization\n",
    "    \n",
    ")\n",
    "\n",
    "# Split the tokenized dataset into train (80%) and test (20%) sets\n",
    "train_test_split = tokenized_datasets.train_test_split(test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "# Assign train and test datasets\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n"
   ],
   "id": "a0127078d7eb56ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/mac/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T07:52:45.004817Z",
     "start_time": "2025-05-22T07:46:47.627600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train from Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ],
   "id": "84a0e0cb57b5229a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='440' max='440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [440/440 05:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.844197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.638600</td>\n",
       "      <td>0.249924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.496300</td>\n",
       "      <td>0.122463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.120746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.120829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.117681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.114949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.078769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.086620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>0.079762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:01]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07876868546009064, 'eval_runtime': 1.6661, 'eval_samples_per_second': 52.218, 'eval_steps_per_second': 3.601, 'epoch': 10.0}\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### run the following command in terminal for visualization\n",
    "% tensorboard --logdir ./logs"
   ],
   "id": "c8054653745a21af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:54:08.998053Z",
     "start_time": "2025-04-23T09:54:08.995229Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Launch TensorBoard with: tensorboard --logdir ./logs\")",
   "id": "3a2d5213b3d200e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launch TensorBoard with: tensorboard --logdir ./logs\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# get attention matrix",
   "id": "55fd20e9491c0d4f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:54:18.787581Z",
     "start_time": "2025-04-23T09:54:18.599992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "code_snippet = \"def add(a, b): return a + b\"\n",
    "inputs = tokenizer(code_snippet, return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(model.device)\n",
    "# Get attention outputs\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "attentions = outputs.attentions  # Attention weights\n",
    "print(attentions)"
   ],
   "id": "b8e4df5715304316",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:08:00.797719Z",
     "start_time": "2025-05-22T08:07:49.885029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Labels for prediction\n",
    "labels = [\"MaxCut\", \"MIS\", \"TSP\", \"Clique\", \"KColor\", \"Factor\",\"ADD\", \"MUL\", \"SUB\", \"VC\"]\n",
    "# Prediction function\n",
    "def predict(code: str):\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\").to(device)\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.softmax(outputs.logits, dim=-1)  # Get probabilities\n",
    "    max_prob, prediction = torch.max(probabilities, dim=-1)\n",
    "\n",
    "    return labels[prediction.item()]\n",
    "\n",
    "train_test_split_1 = tokenized_datasets.train_test_split(test_size=0.2, shuffle=False)\n",
    "test_dataset = train_test_split['test']\n",
    "# Run prediction on the test set and calculate accuracy manually for illustration\n",
    "correct = 0\n",
    "for i in range(len(test_dataset)):\n",
    "    code = test_dataset[i]['code_snippet']\n",
    "    true_label = test_dataset[i]['labels']\n",
    "    predicted_label = predict(code)\n",
    "    if predicted_label == labels[true_label]:\n",
    "        correct += 1\n",
    "    print(f\"True: {labels[true_label]}, Predicted: {predicted_label}\")\n",
    "\n",
    "# Calculate and print accuracy manually\n",
    "accuracy = correct / len(test_dataset)\n",
    "print(f\"Manual Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "id": "fe7baa4469f25880",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: MIS, Predicted: MIS\n",
      "True: SUB, Predicted: SUB\n",
      "True: SUB, Predicted: SUB\n",
      "True: KColor, Predicted: KColor\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: VC, Predicted: VC\n",
      "True: SUB, Predicted: SUB\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: MIS, Predicted: MIS\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: Factor, Predicted: Factor\n",
      "True: SUB, Predicted: SUB\n",
      "True: KColor, Predicted: KColor\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: VC, Predicted: VC\n",
      "True: MIS, Predicted: MIS\n",
      "True: Factor, Predicted: Factor\n",
      "True: TSP, Predicted: TSP\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: MIS, Predicted: MIS\n",
      "True: SUB, Predicted: SUB\n",
      "True: Clique, Predicted: Clique\n",
      "True: Clique, Predicted: Clique\n",
      "True: ADD, Predicted: ADD\n",
      "True: Clique, Predicted: Clique\n",
      "True: ADD, Predicted: ADD\n",
      "True: KColor, Predicted: KColor\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: TSP, Predicted: TSP\n",
      "True: KColor, Predicted: KColor\n",
      "True: KColor, Predicted: KColor\n",
      "True: MIS, Predicted: MIS\n",
      "True: Clique, Predicted: Clique\n",
      "True: TSP, Predicted: TSP\n",
      "True: MUL, Predicted: MUL\n",
      "True: VC, Predicted: VC\n",
      "True: VC, Predicted: VC\n",
      "True: Factor, Predicted: Factor\n",
      "True: VC, Predicted: VC\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: MIS, Predicted: MIS\n",
      "True: MIS, Predicted: MaxCut\n",
      "True: MIS, Predicted: MIS\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: MUL, Predicted: MUL\n",
      "True: KColor, Predicted: KColor\n",
      "True: MIS, Predicted: MIS\n",
      "True: VC, Predicted: VC\n",
      "True: Clique, Predicted: Clique\n",
      "True: Clique, Predicted: Clique\n",
      "True: MaxCut, Predicted: MIS\n",
      "True: VC, Predicted: VC\n",
      "True: Clique, Predicted: Clique\n",
      "True: Clique, Predicted: Clique\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: VC, Predicted: VC\n",
      "True: TSP, Predicted: TSP\n",
      "True: VC, Predicted: VC\n",
      "True: MIS, Predicted: MIS\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: MIS, Predicted: MIS\n",
      "True: TSP, Predicted: TSP\n",
      "True: VC, Predicted: VC\n",
      "True: VC, Predicted: VC\n",
      "True: KColor, Predicted: KColor\n",
      "True: Factor, Predicted: Factor\n",
      "True: KColor, Predicted: KColor\n",
      "True: VC, Predicted: VC\n",
      "True: KColor, Predicted: KColor\n",
      "True: KColor, Predicted: KColor\n",
      "True: TSP, Predicted: TSP\n",
      "True: SUB, Predicted: SUB\n",
      "True: ADD, Predicted: ADD\n",
      "True: Factor, Predicted: Factor\n",
      "True: MIS, Predicted: MIS\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: Factor, Predicted: Factor\n",
      "True: VC, Predicted: VC\n",
      "True: ADD, Predicted: ADD\n",
      "True: VC, Predicted: VC\n",
      "True: TSP, Predicted: TSP\n",
      "True: ADD, Predicted: ADD\n",
      "True: MaxCut, Predicted: MaxCut\n",
      "True: KColor, Predicted: KColor\n",
      "True: TSP, Predicted: TSP\n",
      "Manual Accuracy: 97.70%\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T08:22:01.372450Z",
     "start_time": "2025-05-22T08:21:23.010361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Labels\n",
    "labels = [\"MaxCut\", \"MIS\", \"TSP\", \"Clique\", \"KColor\", \"Factor\", \"ADD\", \"MUL\", \"SUB\", \"VC\"]\n",
    "\n",
    "# Prediction function\n",
    "def predict(code: str):\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.softmax(outputs.logits, dim=-1)\n",
    "    _, prediction = torch.max(probabilities, dim=-1)\n",
    "    return prediction.item()\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in tqdm(range(len(tokenized_datasets))):\n",
    "    code = tokenized_datasets[i][\"code_snippet\"]\n",
    "    true_label = tokenized_datasets[i][\"labels\"]\n",
    "    pred_label = predict(code)\n",
    "\n",
    "    y_true.append(true_label)\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "# Print evaluation report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=labels, digits=3))\n"
   ],
   "id": "5f6788817e290a14",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 434/434 [00:38<00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      MaxCut      0.957     0.971     0.964        68\n",
      "         MIS      0.971     0.957     0.964        70\n",
      "         TSP      1.000     1.000     1.000        44\n",
      "      Clique      1.000     1.000     1.000        33\n",
      "      KColor      1.000     1.000     1.000        58\n",
      "      Factor      1.000     1.000     1.000        31\n",
      "         ADD      1.000     1.000     1.000        28\n",
      "         MUL      1.000     1.000     1.000        27\n",
      "         SUB      1.000     1.000     1.000        28\n",
      "          VC      1.000     1.000     1.000        47\n",
      "\n",
      "    accuracy                          0.988       434\n",
      "   macro avg      0.993     0.993     0.993       434\n",
      "weighted avg      0.989     0.988     0.988       434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T09:54:39.387068Z",
     "start_time": "2025-04-23T09:54:38.842295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save trained model\n",
    "# Save the model and tokenizer locally\n",
    "# Takes some time to store it...\n",
    "model_output_dir = \"./saved_models\"\n",
    "model.save_pretrained(model_output_dir)\n",
    "tokenizer.save_pretrained(model_output_dir)\n",
    "print(f\"Model and tokenizer saved to {model_output_dir}\")"
   ],
   "id": "a87c908341b65f52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./saved_models\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# another code cell, manually train",
   "id": "3935269ea1d50c7c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T11:08:39.781875Z",
     "start_time": "2024-09-16T11:08:21.217515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('csv', data_files={'train': 'train.csv', 'test': 'test.csv'})\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    code_snippet = examples['code_snippet']\n",
    "    return tokenizer(code_snippet, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Specify the fields in the dataset that need to be included\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Define DataLoader\n",
    "train_loader = DataLoader(tokenized_datasets['train'], batch_size=8, shuffle=True)\n",
    "eval_loader = DataLoader(tokenized_datasets['test'], batch_size=8)\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=4)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        # Move input and labels to the device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "# Evaluation loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted = torch.max(outputs.logits, dim=-1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ],
   "id": "7a32e2eec600849a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/107 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88912308141c40e3936daac33422fceb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/55 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ada69eb5706414abff326e2dc11dc2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Target 4 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 53\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[1;32m     52\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(input_ids\u001B[38;5;241m=\u001B[39minput_ids, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\n\u001B[0;32m---> 53\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogits\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# Backward pass and optimization\u001B[39;00m\n\u001B[1;32m     56\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m~/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/torch/nn/modules/loss.py:1188\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m-> 1188\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1189\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1190\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/torch/nn/functional.py:3104\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3102\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3103\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3104\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcross_entropy_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: Target 4 is out of bounds."
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T06:16:25.607205Z",
     "start_time": "2024-09-18T06:16:25.511966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(2, 3), (3, 4), (4, 1)])  # Add multiple edges at onc"
   ],
   "id": "4048e783f244df97",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T06:16:43.689962Z",
     "start_time": "2024-09-18T06:16:43.685737Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "41cd24861d338d23",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeView([(2, 3), (3, 4), (4, 1)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T06:43:03.489103Z",
     "start_time": "2024-10-09T06:43:03.444177Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7f018b5a15e3a352",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/numpy/linalg/linalg.py:2180: RuntimeWarning: divide by zero encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n",
      "/Users/mac/Documents/GitHub/C2Q-Parser/venv/lib/python3.9/site-packages/numpy/linalg/linalg.py:2180: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n",
      "/var/folders/ys/tg4mzr093dsgjjl04f5n863c0000gn/T/ipykernel_74012/989223126.py:18: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plot_bloch_multivector(state).show()\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
